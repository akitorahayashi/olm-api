services:
  ollama:
    image: ollama:latest
    build:
      context: ./ollama
      args:
        - BUILT_IN_OLLAMA_MODELS=${BUILT_IN_OLLAMA_MODELS}
    entrypoint: ollama
    command: serve
    volumes:
      - ollama-data:/root/.ollama
    environment:
      - OLLAMA_CONTEXT_LENGTH=${OLLAMA_CONTEXT_LENGTH}
      - OLLAMA_NUM_PARALLEL=${OLLAMA_NUM_PARALLEL}
      - OLLAMA_MAX_QUEUE=${OLLAMA_MAX_QUEUE}
      - OLLAMA_FLASH_ATTENTION=${OLLAMA_FLASH_ATTENTION}
      - OLLAMA_KEEP_ALIVE=${OLLAMA_KEEP_ALIVE}
      - OLLAMA_MAX_LOADED_MODELS=${OLLAMA_MAX_LOADED_MODELS}
      - OLLAMA_GPU_OVERHEAD=${OLLAMA_GPU_OVERHEAD}
      - OLLAMA_KV_CACHE_TYPE=${OLLAMA_KV_CACHE_TYPE}
    healthcheck:
      test: [ "CMD", "ollama", "list" ]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s
    restart: unless-stopped

  api:
    image: olm-api:latest
    build:
      context: .
      dockerfile: Dockerfile
      target: production
    ports:
      - "${HOST_BIND_IP}:${HOST_PORT}:8000"
    depends_on:
      ollama:
        condition: service_healthy
    env_file:
      - .env
    environment:
      - DATABASE_URL=sqlite:///data/sqlite.db
    healthcheck:
      test: [ "CMD", "python", "-c", "import sys, urllib.request; sys.exit(0) if urllib.request.urlopen('http://localhost:8000/health').getcode() == 200 else sys.exit(1)" ]
      interval: 30s
      timeout: 10s
      start_period: 5s
      retries: 3
    restart: unless-stopped

volumes:
  ollama-data:
    driver: local
    name: ${PROJECT_NAME}-ollama-data
    external: false
