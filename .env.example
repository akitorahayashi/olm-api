# --- Ollama settings ---
# BUILT_IN_OLLAMA_MODEL: Dockerイメージに組み込まれ、常に利用可能であるべきベースモデル。このモデルはAPIから削除できません。
BUILT_IN_OLLAMA_MODEL=qwen3:0.6b

# --- API server settings ---
HOST_BIND_IP=127.0.0.1
HOST_PORT=8000

# --- Ollama concurrency settings ---
# Maximum simultaneous API requests
OLLAMA_CONCURRENT_REQUEST_LIMIT=2
# Maximum parallel processes inside Ollama
OLLAMA_NUM_PARALLEL=2
# Maximum number of models loaded in VRAM
OLLAMA_MAX_LOADED_MODELS=1

# --- Ollama settings ---
# OLLAMA_HOST: URL to Ollama service 
# For production: use external Ollama server (e.g., http://your-ollama-server:11434)
# For development: use http://ollama:11434 (container) or http://host.docker.internal:11434 (host)
OLLAMA_HOST=http://your-ollama-server:11434

# --- Database settings ---
POSTGRES_USER=user
POSTGRES_PASSWORD=password
POSTGRES_DB_NAME=olm-api
DATABASE_URL=postgresql+psycopg://${POSTGRES_USER}:${POSTGRES_PASSWORD}@db:5432/${POSTGRES_DB_NAME}
